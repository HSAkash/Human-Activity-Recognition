{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install tensorflow numpy glob tqdm scikit-learn Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYdlqGOn6vLQ"
      },
      "source": [
        "# Bin image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Google drive link (Segment BIN images): \n",
        "* https://drive.google.com/file/d/1-1DpWRCnXLjVmek41ufd4FWbjdnhJVgy/view?usp=sharing\n",
        "```same folder\n",
        "|\n",
        "├─05_feature_extraction.ipynb\n",
        "│\n",
        "├─env\n",
        "├─aug_seg_bin\n",
        "├─aug_seg_rgb\n",
        "|  \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EW09LJKsZH21"
      },
      "outputs": [],
      "source": [
        "# ! unzip -q  \"/content/drive/MyDrive/Colab Notebooks/Human_Activity_Recognition/aug_seg_bin.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Bmw4vhBcZTV4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TlGcMJGxbnpG"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE_H = 480\n",
        "IMG_SIZE_W = 640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHJUUXK1boAP",
        "outputId": "1e99df58-01c6-4c88-b42b-84e34d10fccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "def build_feature_extractor_imagenet():\n",
        "    feature_extractor = tf.keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE_H, IMG_SIZE_W, 3),\n",
        "    )\n",
        "    preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
        "    inputs = tf.keras.Input((IMG_SIZE_H, IMG_SIZE_W, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return tf.keras.Model(inputs, outputs, name=\"feature_extractor_imgnet\")\n",
        "\n",
        "feature_extractor_imagenet = build_feature_extractor_imagenet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E6bhkIjVbr5R"
      },
      "outputs": [],
      "source": [
        "def get_images(img_paths):\n",
        "    images = []\n",
        "    for img_path in img_paths:\n",
        "        img =  Image.open(img_path)\n",
        "        img = np.asarray(img, dtype=np.float32)\n",
        "        images.append(img)\n",
        "        del img\n",
        "    return np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DrEzMhC2btbJ"
      },
      "outputs": [],
      "source": [
        "source_dir = \"aug_seg_bin\"\n",
        "dist_dir = \"aug_feature_seg_bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hLeqE4pdzzm",
        "outputId": "1f40e1a6-13f9-425c-c574-2d9dd82ec7e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15582"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_img_bin_dirs = glob(f\"{source_dir}/*/*\")\n",
        "len(all_img_bin_dirs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lq2BWSykbvRY"
      },
      "outputs": [],
      "source": [
        "def save_feature(img_paths, features):\n",
        "    os.makedirs(os.path.dirname(img_paths[0].replace(source_dir, dist_dir)), exist_ok=True)\n",
        "    for img_path, feature in zip(img_paths, features):\n",
        "        dits_path = img_path.replace(source_dir, dist_dir).replace('.jpg', '.npy')\n",
        "        np.save(dits_path, feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "9f2bad304cb2417688d93383779e88f0",
            "c1a507baa13b4068aa459fe042579ecc",
            "9e35293a18174bfc9c53a3e261464829",
            "c382397b0cc74d858ff51fabdc4718ab",
            "1e8e793f91624d4595c46db8ba15fd29",
            "5ba4a9e4609b416d996b3096aaed0f88",
            "7bccb21b460641ce8907957a6417dad2",
            "52b6ca346d4845229d0f73a76665970f",
            "99fdbc4fe7654d43bdf412a14419c223",
            "71c3f062dedd416893372ac64d03e224",
            "96b3dd5fd94c43aa8b69076c509edfa4"
          ]
        },
        "id": "EcEikp00b7s1",
        "outputId": "76c015ea-3f96-41ad-bd9c-87e32172c637"
      },
      "outputs": [],
      "source": [
        "for img_dir_path in tqdm(all_img_bin_dirs):\n",
        "    img_paths = glob(f'{img_dir_path}/*')\n",
        "    if os.path.exists(img_dir_path.replace(source_dir, dist_dir)):\n",
        "        continue\n",
        "    images = get_images(img_paths)\n",
        "    if len(images.shape) == 3 :\n",
        "        images = np.expand_dims(images, axis=-1)\n",
        "        images = np.repeat(images, 3, axis=-1)\n",
        "    features = feature_extractor_imagenet(images)\n",
        "    features = features.numpy()\n",
        "    save_feature(img_paths, features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cydeQdDmb-yI"
      },
      "outputs": [],
      "source": [
        "# ! zip -q -r \"aug_feature_seg_bin.zip\" \"aug_feature_seg_bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eahjN2dFb_Mq"
      },
      "outputs": [],
      "source": [
        "# ! cp \"aug_feature_seg_bin.zip\"  \"/content/drive/MyDrive/Colab Notebooks/Human_Activity_Recognition/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEpN1G_ecCkJ"
      },
      "source": [
        "# RGB img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Google drive link (Segment RGB images): \n",
        "* https://drive.google.com/file/d/1erUQxsy35emFLkKUKYtwsbvm9xj7yfeF/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0r5l-EfwcFKX"
      },
      "outputs": [],
      "source": [
        "# ! unzip -q \"/content/drive/MyDrive/Colab Notebooks/Human_Activity_Recognition/aug_seg_rgb.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7Q3ka5ecHgL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS2DbScacJE1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ed52_TqcKTT"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE_H = 480\n",
        "IMG_SIZE_W = 640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBsvWC2tcL08"
      },
      "outputs": [],
      "source": [
        "def build_feature_extractor_imagenet():\n",
        "    feature_extractor = tf.keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE_H, IMG_SIZE_W, 3),\n",
        "    )\n",
        "    preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
        "    inputs = tf.keras.Input((IMG_SIZE_H, IMG_SIZE_W, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return tf.keras.Model(inputs, outputs, name=\"feature_extractor_imgnet\")\n",
        "\n",
        "feature_extractor_imagenet = build_feature_extractor_imagenet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07WrUvupcNYn"
      },
      "outputs": [],
      "source": [
        "def get_images(img_paths):\n",
        "    images = []\n",
        "    for img_path in img_paths:\n",
        "        img =  Image.open(img_path)\n",
        "        img = np.asarray(img, dtype=np.float32)\n",
        "        images.append(img)\n",
        "        del img\n",
        "    return np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nNbtUWOcPEz"
      },
      "outputs": [],
      "source": [
        "source_dir = \"aug_seg_rgb\"\n",
        "dist_dir = \"aug_feature_seg_rgb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX6--OWGetH7"
      },
      "outputs": [],
      "source": [
        "all_img_rgb_dirs = glob(f\"{source_dir}/*/*\")\n",
        "len(all_img_rgb_dirs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mCkxAC9cQpp"
      },
      "outputs": [],
      "source": [
        "def save_feature(img_paths, features):\n",
        "    os.makedirs(os.path.dirname(img_paths[0].replace(source_dir, dist_dir)), exist_ok=True)\n",
        "    for img_path, feature in zip(img_paths, features):\n",
        "        dits_path = img_path.replace(source_dir, dist_dir).replace('.jpg', '.npy')\n",
        "        np.save(dits_path, feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvP9VE2GcSXS"
      },
      "outputs": [],
      "source": [
        "for img_dir_path in tqdm(all_img_rgb_dirs):\n",
        "    img_paths = glob(f'{img_dir_path}/*')\n",
        "    if os.path.exists(img_dir_path.replace(source_dir, dist_dir)):\n",
        "        continue\n",
        "    images = get_images(img_paths)\n",
        "    if len(images.shape) == 3 :\n",
        "        images = np.expand_dims(images, axis=-1)\n",
        "        images = np.repeat(images, 3, axis=-1)\n",
        "    features = feature_extractor_imagenet(images)\n",
        "    features = features.numpy()\n",
        "    save_feature(img_paths, features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7v4Y34xcUGg"
      },
      "outputs": [],
      "source": [
        "# ! zip -q -r \"aug_feature_seg_rgb.zip\" \"aug_feature_seg_rgb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dta0s4uFcVwF"
      },
      "outputs": [],
      "source": [
        "# ! cp \"aug_feature_seg_rgb.zip\"  \"/content/drive/MyDrive/Colab Notebooks/Human_Activity_Recognition/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/yato/ML/human-activity-recognition/env/lib/python3.12/site-packages/cv2/qt/plugins\"\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def resize_with_padding(image, target_height, target_width):\n",
        "    # Get the original dimensions\n",
        "    original_height, original_width = image.shape[:2]\n",
        "\n",
        "    # Calculate the scaling factor while maintaining aspect ratio\n",
        "    scale = min(target_width / original_width, target_height / original_height)\n",
        "    \n",
        "    # Compute the new size while maintaining the aspect ratio\n",
        "    new_width = int(original_width * scale)\n",
        "    new_height = int(original_height * scale)\n",
        "    \n",
        "    # Resize the image\n",
        "    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Create a black canvas of the target size\n",
        "    canvas = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
        "\n",
        "    # Calculate the top-left corner position to center the image on the canvas\n",
        "    x_offset = (target_width - new_width) // 2\n",
        "    y_offset = (target_height - new_height) // 2\n",
        "\n",
        "    # Place the resized image onto the black canvas\n",
        "    canvas[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized_image\n",
        "\n",
        "    return canvas\n",
        "\n",
        "# Load your image (replace 'image.jpg' with the path to your image)\n",
        "# image = cv2.imread('image.jpg')\n",
        "# make a fake image\n",
        "image = np.ones((1920,1080, 3), dtype=np.uint8)*255\n",
        "\n",
        "\n",
        "# Define your target size\n",
        "target_height1, target_width1 = 250, 100\n",
        "target_height2, target_width2 = 100, 250\n",
        "\n",
        "# Resize and pad the image to both target sizes\n",
        "resized_image1 = resize_with_padding(image, target_height1, target_width1)\n",
        "resized_image2 = resize_with_padding(image, target_height2, target_width2)\n",
        "\n",
        "# Save or display the results\n",
        "cv2.imwrite('resized_250x100.jpg', resized_image1)\n",
        "cv2.imwrite('resized_100x250.jpg', resized_image2)\n",
        "cv2.imshow('Resized 250x100', resized_image1)\n",
        "cv2.imshow('Resized 100x250', resized_image2)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]]], dtype=int16)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = np.load(\"../data/keypointDataset/class_01/00000/003.npy\")\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([], dtype=int16)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.load(\"../data/boxDataset/class_01/00000/003.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e8e793f91624d4595c46db8ba15fd29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b6ca346d4845229d0f73a76665970f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ba4a9e4609b416d996b3096aaed0f88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71c3f062dedd416893372ac64d03e224": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bccb21b460641ce8907957a6417dad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96b3dd5fd94c43aa8b69076c509edfa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99fdbc4fe7654d43bdf412a14419c223": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e35293a18174bfc9c53a3e261464829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52b6ca346d4845229d0f73a76665970f",
            "max": 15582,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99fdbc4fe7654d43bdf412a14419c223",
            "value": 0
          }
        },
        "9f2bad304cb2417688d93383779e88f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1a507baa13b4068aa459fe042579ecc",
              "IPY_MODEL_9e35293a18174bfc9c53a3e261464829",
              "IPY_MODEL_c382397b0cc74d858ff51fabdc4718ab"
            ],
            "layout": "IPY_MODEL_1e8e793f91624d4595c46db8ba15fd29"
          }
        },
        "c1a507baa13b4068aa459fe042579ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ba4a9e4609b416d996b3096aaed0f88",
            "placeholder": "​",
            "style": "IPY_MODEL_7bccb21b460641ce8907957a6417dad2",
            "value": "  0%"
          }
        },
        "c382397b0cc74d858ff51fabdc4718ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71c3f062dedd416893372ac64d03e224",
            "placeholder": "​",
            "style": "IPY_MODEL_96b3dd5fd94c43aa8b69076c509edfa4",
            "value": " 0/15582 [00:26&lt;?, ?it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
